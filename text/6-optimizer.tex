\section{Методы стохастической оптимизации}
	Для обучения глубоких нейросетей применяется метод обратного распространения ошибки, который позволяет расчитать градиенты весов, и различные методы стохастической оптимизации первого порядка. В данной работе для обучения моделей применялось 2 алгоритма оптимизации под названиями "RMSprop" и "Adam".
	\subsection{RMSprop}
	\subsection{Adam}
	