\documentclass[a4paper]{article}
\usepackage[12pt]{extsizes}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage{amssymb,amsmath,mathtext}
\usepackage{indentfirst,amsfonts}
\usepackage[english, russian]{babel}
\usepackage{setspace,amsmath}
\usepackage{graphicx}
\usepackage[left=30mm, top=20mm, right=10mm, bottom=20mm, nohead, footskip=10mm]{geometry} % настройки полей документа

\graphicspath{{graphs/}}

\begin{document}
	\begin{titlepage} % начало документа
		
		% НАЧАЛО ТИТУЛЬНОГО ЛИСТА
		\begin{center}
			\footnotesize{ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ БЮДЖЕТНОЕ ОБРАЗОВАТЕЛЬНОЕ }\\ 
			\footnotesize{УЧРЕЖДЕНИЕ ВЫСШЕГО ОБРАЗОВАНИЯ}\\
			\small{«МОСКОВСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ}\\
			\small{имени М.В.ЛОМОНОСОВА»}\\
			\hfill \break
			\normalsize{ФИЗИЧЕСКИЙ ФАКУЛЬТЕТ}\\
			\hfill \break
			\normalsize{КАФЕДРА МАТЕМАТИЧЕСКОГО МОДЕЛИРОВАНИЯ И ИНФОРМАТИКИ}\\
			\hfill \break
			\hfill \break
			\hfill \break
			\hfill \break
			\hfill \break
			\hfill \break
			\large{\textbf{Нейросетевой синтез текстур с трендами}}\\
		\end{center}
		
		\hfill \break
		
		\begin{flushright}
			Выполнил студент \\
			\hfill \break
			435 группы:\\
			\hfill \break
			Будакян Я. С.\\
			\hfill \break
			\hfill \break
			\hfill \break
			Научный руководитель: \\
			\hfill \break
			к.т.н., доц. Грачев Е. А.\\
			\hfill \break
		\end{flushright}
		
		\hfill \break
		\hfill \break
		\hfill \break
		\hfill \break
		\hfill \break
		\hfill \break
		
		\begin{center}
			Москва \\
			\hfill \break
			2017 
		\end{center}
		
		\thispagestyle{empty} % выключаем отображение номера для этой страницы
		
		% КОНЕЦ ТИТУЛЬНОГО ЛИСТА
		
	\end{titlepage}  % КОНЕЦ ДОКУМЕНТА !
	%учитываем титульный лист в нумерации
	\setcounter{page}{2}
	\section{Введение}
		Цель работы состоит в построении процедуры синтеза изображений среды, которые будут содержать в себе тренд. Под текстурой с трендом понимается изображение, в котором есть изменение некоторой статистической характеристики вдоль одного из направлений. Такими характеристиками, например, могут быть изменение интенсивности появления частиц среды или изменение пористости среды. \\
		\begin{figure}[h]
			\centering{\includegraphics[width=0.35\linewidth]{trend-sample}}
			\caption{Пример текстуры с трендом интенсивности частиц.}
		\end{figure}
	\section{Математическая постановка}
		Рассмотрим гипотетическое многомерное пространство, в котором находятся все изображения. Тогда обучающая выборка изображений с трендами задает в этом пространстве вероятностное распределение $P_X$, в котором точки, соответствующие изображениям из выборки, имеют высокую вероятность, а остальные - очень низкую. Это так называемая вероятностная постановка задачи обучения \cite{Voron-ML, GAN} . Тогда с математической точки зрения задача синтеза текстуры с трендом сводится к синтезу случайного изображения $X'$, принадлежащего распределению, близкому к задаваемому обучающей выборкой:
		$$ P_{X'} \approx P_X,$$
		где $P_X$ - распределение изображений с трендами, удовлетворяющих следующим ограничениям (для упрощения задачи):
		\begin{itemize}
			\item Это монохромные изображения 256 x 256 пикселей
			\item Изменяющимся свойством является интенсивность появления частиц $\lambda$
			\item Тренд является линейным и направлен вдоль оси x: 
			$ \lambda = \lambda_0 + kx $
		\end{itemize}
	\section{Существующие подходы к решению задачи}
		Есть несколько подходов к решению задач подобного рода:
		\begin{itemize}
			\item 'Классический' статистический подход
			\item Базовый нейросетевой подход
			\item Генеративные состязательные сети (GAN)
		\end{itemize}
		\subsection{'Классический' статистический подход}
			\begin{itemize}
				\item Вводится параметризированное семейство распределений вероятности $P_{\theta}(x)$
				\item Параметры $\theta$ находятся из обучающей выборки:
				$$ \mathcal{L}_{\theta}(D) = \prod_{x \in D} P_{\theta}(x) $$
				$$ \theta^{*} = \underset{\theta}{\arg\max} \mathcal{L}_{\theta}(D)$$
				\item Генерируется текстура из распределения $ P_{\theta^{*}}$
			\end{itemize}
			Этот подход приводит к проблемам:
			\begin{itemize}
				\item Пространство параметров $\theta$ может быть огромной размерности
				\item Известной параметрической модели распределения может вообще не существовать
			\end{itemize}
			Простой пример - синтез человеческих лиц: с помощью классического подхода эта задача не была решена с хорошим качеством.
		\subsection{Базовый нейросетевой подход}
			\begin{itemize}
				\item Вводится параметризированное семейство распределений вероятности $P_{\theta}(x)$
				\begin{itemize}
					\item Вводятся скрытые переменные $V$ и функция(нейросеть) для получения $x$ из $V$ (фактически, классификация, развернутая в другую сторону)
				\end{itemize}
				\item Определяются параметры распределения (т.е. обучение нейросети)
				\item Генерируется выборка из $ P_{\theta^{*}}$
			\end{itemize}
			Этот подход возможен, однако на практике трудноосуществим \cite{GAN-2}.
		\subsection{GAN - генеративные состязательные сети}
				Вернемся к изначальной задаче: найти процеруду генерирования $X'$ так, чтобы $ P_{X'} \approx P_X$.
				Переформулируем:
				$$ \rho(P_{X'}, P_X) \longrightarrow \underset{P_{X'}}{\min} $$
				Введем некоторые скрытые переменные с фиксированным распределением, например
				$$ V \sim U^n [-1, 1], $$
				и параметризированную процедуру генерации:
				$$ X' = g_{\theta}(V) $$
				Переформулируем:
				$$ \rho(P_{X'}, P_X) \longrightarrow \underset{P_{X'}}{\min} $$
				$$ \rho(g_{\theta}(V), P_X) \longrightarrow \underset{g_{\theta}(V)}{\min} $$
				$$ \rho(g_{\theta}(V), P_X) \longrightarrow \underset{\theta}{\min} $$
				Возникает вопрос: что использовать в качестве метрики похожести двух распределений $\rho$, где одно из распределений задано обучающей выборкой.
				В качестве такой метрики можно использовать функцию потерь обученного классификатора. Тогда задача примет вид:
				$$ \rho(P_{X'}, P_X) \longrightarrow \min \Leftrightarrow L \longrightarrow \max, $$
				где $L$ - функция потерь обученного классификатора.
				Соответственно, можно ввести две нейросети:
					\begin{itemize}
						\item $d_{\zeta}(x)$ - классификатор для измерения расстояния, \textbf{'дискриминатор'}
						\item $g_{\theta}(x)$ - сеть, трансформирующая $V$ в $X'$, \textbf{'генератор'}
					\end{itemize}
					Суть использования двух сетей состоит в том, что они обучаются совместно, конкурируя друг с другом: генератор пытается имитировать целевое распределение, а дискриминатор пытается классифицировать поступающие от генератора и из обучающей выборки изображения на 2 класса: реальные (из изначального распределения $P_X$) и ложные (из $P_X'$, т.е. произведенные генератором).
					Для дальнейшего рассмотрения введем функцию потерь дискриминатора(например, logloss):
					$$ L(X, X') = \frac{1}{2} \mathbb{E}_{X} l(d_{\zeta}(x), 1) + \frac{1}{2} \mathbb{E}_{X'} l(d_{\zeta}(x'), 0) = $$
					$$ = -\frac{1}{2} (\mathbb{E}_{X} \log d_{\zeta}(x) + \mathbb{E}_{X'} \log (1 - d_{\zeta}(x'))) = $$
					$$ =  -\frac{1}{2} (\mathbb{E}_{X} \log d_{\zeta}(x) + \mathbb{E}_{V} \log (1 - d_{\zeta}(g_{\theta}(v)))) = $$
					$$ = L(\zeta, \theta) .$$
					$l(d_{\zeta}(x), 1)$ и $ l(d_{\zeta}(x'), 0) $ здесь - это потери при неправильной классификации реального и ложного изображений соответственно.
					Функция потерь обученного классификатора:
					$$ L^*(\theta) = \underset{\zeta}{\min} L(\zeta, \theta) $$
					Соответственно,
					$$ \underset{\zeta}{\min} L(\zeta, \theta) \longrightarrow \underset{\theta}{\max} $$
					$$ \theta^* = \underset{\theta}{\arg\max} \left[ \underset{\zeta}{\min} L(\zeta, \theta) \right] $$
					Определим оптимальный дискриминатор:
					$$ d^*_{\theta} = d_{\zeta^*(\theta)} $$
					$$ \zeta^*(\theta) =  \underset{\zeta}{\arg\min} L(\zeta, \theta)$$
	\section{Обучение GAN}
		Итак, задача обучения GAN свелась к нахождению
		$$ \theta^* = \underset{\theta}{\arg\max} \left[ \underset{\zeta}{\min} L(\zeta, \theta) \right] $$
		Решить ее можно, например, методом стохастического градиентного спуска:
		$$ \Delta \theta \sim \nabla L(\zeta^*(\theta), \theta)$$
		Для малых изменений $\Delta \theta$:
		$$ \nabla L(\zeta^*(\theta), \theta) \approx \nabla L(\zeta^*(\theta), \theta + \Delta \theta) $$
		В итоге, процесс обучения принимает следующий вид:
		\begin{itemize}
				\item Обучаем дискриминатор при фиксированном генераторе
				\item Обучаем генератор при фиксированном дискриминаторе
				\item Повторяем до сходимости параметров обеих моделей
		\end{itemize}
		\begin{figure}
			\begin{center}
				\includegraphics[width=0.4\linewidth]{gan-training}
			\end{center}
			\caption{Схематическое изображение процесса обучения GAN}
		\end{figure}
	\section{pix2pix GAN}
		Для решения задачи было попробовано применить модификацию GAN-сети по названием "pix2pix GAN". Для нее функционал потерь выглядит следующим образом: $$ L(G, D) = L_{adv}(G, D) + \eta \mathbb{E}_{p_{data}(s_1, s_2, r)} (\parallel r - G(s_1, s_2) \parallel_1)$$
		$$ L_{adv}(G, D) = \mathbb{E}_{p_{data}(s_1, s_2, r)}\log D(s_1, s_2, r) +  \mathbb{E}_{p_{data}(s_1, s_2)} \log (1 - D(s_1, s_2, G(s_1, s_2)))$$
		где G, D - генератор и дискриминатор, $(s_1, s_2, r)$ - тройка изображений (интенсивность слева, справа и реальное изображение с трендом),  $\mathbb{E}_{p_{data}(s_1, s_2, r)}$ - мат. ожидание логарифмического правдоподобия того, что тройка изображений $(s_1, s_2, r)$ принадлежит вероятностному распределению реальных троек $p_{data}(s_1, s_2, r)$, а $p_{data}(s_1, s_2)$ соответствует распределению реальных изображений $s_1, s_2$.
		\begin{figure}[h]
			\begin{center}
				\includegraphics[width=0.75\linewidth]{p2p-gen}
			\end{center}
			\caption{Вход и желаемый выход нейросети}
		\end{figure}
	\section{Критерий качества}
		После обучения генератора, необходимо проверить, что сгенерированные им изображения действительно имеют искомые характеристики. Для этого нужно ввести специальную метрику, которая будет учитывать наличие в изображении тренда интенсивности частиц. Было решено использовать среднюю плотность черных пикселей в некотором окне, и проходить этим окном по изображению (Рис. 4):
		$$\xi_k = \frac{1}{H w}{\sum_{i=k}^{k+w} \sum_{j=0}^{H}\left| \frac{x(i, j) - 255}{255} \right|}, $$$$k = \overline{1, W - w + 1} $$
		\begin{figure}[h!]
			\begin{center}
				\includegraphics[width=0.35\linewidth]{metrics}
			\end{center}
			\caption{Прохождение окном, W, H - размеры изображения, w - ширина окна}
		\end{figure}
		\\
		Построив график $\xi(k)$ можно увидеть, как меняется плотность пикселей и прослеживается ли тренд. В качестве метрики можно взять среднеквадратичную ошибку:
		$$ \xi = \frac{1}{W-w}\sum_{k=1}^{W-w+1} (\xi_k - \xi_{0k})^2,$$
		где $\xi_{0k}$ - это $\xi_k$, усредненное по примерам из обучающей выборки. Соответственно, чем меньше значение метрики, тем лучше тренд, присутствующий на сгенерированном изображении, приближает искомый.
	\section{Результаты}
		Было проведено обучение нейросети описанной архитектуры при различных гиперпараметрах. Обучающей выборкой был массив из 3500 троек изображений. Примеры сгенерированных текстур приведены на (Рис. 5).
		\begin{figure}
				\begin{minipage}{0.3\linewidth}
					\centering{\includegraphics[width=0.75\linewidth]{nf8} \\ nf8}
				\end{minipage}
				\hfill
				\begin{minipage}{0.3\linewidth}
					\centering{\includegraphics[width=0.75\linewidth]{nf16} \\ nf16}
				\end{minipage}
				\hfill
				\begin{minipage}{0.3\linewidth}
					\centering{\includegraphics[width=0.75\linewidth]{nf16_woUnet} \\ nf16-woUnet}
				\end{minipage}
				\hfill
				\begin{minipage}{0.3\linewidth}
					\centering{\includegraphics[width=0.75\linewidth]{nf16_3x3_woUnet} \\ nf16-3x3-woUnet}
				\end{minipage}
				\hfill
				\begin{minipage}{0.3\linewidth}
					\centering{\includegraphics[width=0.75\linewidth]{nf32} \\ nf32}
				\end{minipage}
				\hfill
				\begin{minipage}{0.3\linewidth}
					\centering{\includegraphics[width=0.75\linewidth]{nf32_woUnet} \\ nf32-woUnet}
				\end{minipage}
				\caption{Примеры сгенерированных текстур}
			\end{figure}
			Была подсчитана введенная метрика для сгенерированных наборов текстур. Графики плотности черных пикселей в зависимости от сдвига окна, квадратичного отклонения от тренда и сами значения метрики приведены на (Рис. 6, 7, 8, 9) и в (Таб. 1, 2)
			\begin{center}
				\begin{figure}
					\includegraphics[width=0.95\linewidth,height=0.5\textwidth]{tr_1}
					\caption{Плотность черных пикселей в окне в зависимости от сдвига окна}
				\end{figure}
			\end{center}
			\begin{table}[h]
				\begin{center}
					\begin{tabular}{|c|c|}
						\hline
						Сеть & Метрика \\
						\hline
						nf8 & 0.00825\\
						\hline
						nf32 & 0.00549\\
						\hline
						nf32-woUnet & 0.00688\\
						\hline
					\end{tabular}
					\caption{Значения введенной метрики для разных сетей}
				\end{center}
			\end{table}
			\begin{center}
				\begin{figure}
					\includegraphics[width=0.95\linewidth,height=0.5\textwidth]{tr_2}
					\caption{Плотность черных пикселей в окне в зависимости от сдвига окна}
			\end{figure}
			\end{center}
			\begin{table}[h]
				\begin{center}
					\begin{tabular}{|c|c|}
						\hline
						Сеть & Метрика \\
						\hline
						nf16 & 0.00606\\
						\hline
						nf16-woUnet & 0.00881\\
						\hline
						nf16-3x3-woUnet & 0.01034\\
						\hline
					\end{tabular}
					\caption{Значения введенной метрики для разных сетей}
				\end{center}
			\end{table}
			\begin{center}
				\begin{figure}[h]
					\includegraphics[width=0.95\linewidth,height=0.5\textwidth]{earr_1}
					\caption{Квадратичное отклонение от тренда для разных сетей}
				\end{figure}
				\begin{figure}[h]
					\includegraphics[width=0.95\linewidth,height=0.5\textwidth]{earr_2}
					\caption{Квадратичное отклонение от тренда для разных сетей}
					\end{figure}
			\end{center}
	\section{Выводы}
		В работе было:
		\begin{itemize}
			\item Исследовано применение архитектуры GAN для синтеза текстур с трендами
			\item Получены результаты синтеза при нескольких наборах гиперпараметров сети
			\item Проведено измерение качества генерации для каждого из наборов, используя специально введенную метрику
		\end{itemize}
	\section{Заключение}
		Полученные результаты показывают, что в принципе нейросеть способна уловить тренд и воспроизвести его, однако на данный момент качество генерации относительно невысоко. Необходимо провести дальнешее исследование оптимальных гиперпараметров, и, возможно, увеличить объем обучающей выборки. Также можно провести аналогичные эксперименты с другими архитектурами генераторов.
	\begin{thebibliography}{99}
		\bibitem{Voron-ML}  Воронцов К. В., "Математические методы обучения по прецедентам (теория обучения машин)".
		\bibitem{GAN} Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bign Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, "Generative Adversarial Nets". arXiv: 1406.2661 [stat.ML], 2014
		\bibitem{GAN-2} Goodfellow, Ian, et al. "Generative adversarial nets". Advances in neural information processing systems. 2014
		\bibitem{p2p} Pedro Costa, Adrian Galdran, Maria Inês Meyer, Michael David Abràmoff, Meindert Niemeijer, Ana Maria Mendonça, Aurélio Campilho, "Towards Adversarial Retinal Image Synthesis". arXiv: 1701.08974 [cs.CV], 2017
	
\end{thebibliography}
\end{document}