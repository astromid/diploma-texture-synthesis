{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pix2pix(U-Net + GAN) experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import objectives\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose, Cropping2D\n",
    "from keras.layers.core import Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# U-Net Generator\n",
    "def g_unet(nf, model_name, in_ch=1, out_ch=1, batch_size=1, alpha=0.2):\n",
    "    ''' параметры:\n",
    "    input shape = (100, 100, in_ch)\n",
    "    output = (100, 250, out_ch)\n",
    "    nf - число фильтров на входном слое\n",
    "    alpha - параметр LeakyReLU\n",
    "    '''\n",
    "    i = Input(shape=(100, 100, in_ch))\n",
    "    # (100, 100, in_ch)\n",
    "    \n",
    "    conv1 = Conv2D(nf, (6, 6), padding='same', strides=(5, 5))(i)\n",
    "    conv1 = BatchNormalization(axis=3)(conv1)\n",
    "    x = LeakyReLU(alpha)(conv1)\n",
    "    # (20, 20, nf)\n",
    "    \n",
    "    conv2 = Conv2D(nf*5, (6, 6), padding='same', strides=(5, 5))(x)\n",
    "    conv2 = BatchNormalization(axis=3)(conv2)\n",
    "    x = LeakyReLU(alpha)(conv2)\n",
    "    # (4, 4, nf*5)\n",
    "    \n",
    "    conv3 = Conv2D(nf*10, (3, 3), padding='same', strides=(2, 2))(x)\n",
    "    conv3 = BatchNormalization(axis=3)(conv3)\n",
    "    x = LeakyReLU(alpha)(conv3)\n",
    "    # (2, 2, nf*10)\n",
    "\n",
    "    conv4 = Conv2D(nf*10, (2, 2), padding='valid', strides=(1, 1))(x)\n",
    "    conv4 = BatchNormalization(axis=3)(conv4)\n",
    "    x = LeakyReLU(alpha)(conv4)\n",
    "    # (1, 1, nf*10)\n",
    "\n",
    "    dconv1 = Conv2DTranspose(nf*10, (2, 2), strides=(1, 1))(x)\n",
    "    dconv1 = BatchNormalization(axis=3)(dconv1)\n",
    "    dconv1 = Dropout(0.5)(dconv1)\n",
    "    x = concatenate([dconv1, conv3], axis=3)\n",
    "    x = LeakyReLU(alpha)(x)\n",
    "    # (2, 2, nf*(10 + 10))\n",
    "\n",
    "    dconv2 = Conv2DTranspose(nf*5, (2, 2), strides=(2, 2))(x)\n",
    "    dconv2 = BatchNormalization(axis=3)(dconv2)\n",
    "    x = concatenate([dconv2, conv2], axis=3)\n",
    "    x = LeakyReLU(alpha)(x)\n",
    "    # (4, 4, nf*(5 + 5))\n",
    "\n",
    "    dconv3 = Conv2DTranspose(nf, (2, 2), strides=(5, 5))(x)\n",
    "    dconv3 = BatchNormalization(axis=3)(dconv3)\n",
    "    x = concatenate([dconv3, conv1], axis=3)\n",
    "    x = LeakyReLU(alpha)(x)\n",
    "    # (20, 20, nf*(1 + 1))\n",
    "\n",
    "    dconv4 = Conv2DTranspose(out_ch, (2, 2), strides=(13, 5))(x)\n",
    "    # (260, 100, out_ch)\n",
    "    \n",
    "    dconv4 = Cropping2D((5, 0))(dconv4)\n",
    "    # (250, 100, out_ch)\n",
    "\n",
    "    out = Activation('tanh')(dconv4)\n",
    "    unet = Model(i, out, name=model_name)\n",
    "    \n",
    "    return unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "def discriminator(nf, a_ch=1, b_ch=1, c_ch=1, opt=Adam(lr=2e-4, beta_1=0.5), alpha=0.2, model_name='d'):\n",
    "    ''' параметры:\n",
    "    a_ch - число каналов первого изображения\n",
    "    b_ch - число каналов второго\n",
    "    c_ch - третьего\n",
    "    nf - число фильтров на входном слое\n",
    "    alpha - параметр LeakyReLU\n",
    "    '''\n",
    "    i1 = Input(shape=(100, 100, a_ch + b_ch))\n",
    "    # (100, 100, a_ch + b_ch) - side1 + side2\n",
    "    \n",
    "    i2 = Input(shape=(500, 100, c_ch))\n",
    "    # (500, 100, c_ch) - panorama\n",
    "    \n",
    "    conv0 = Conv2D(c_ch, (6,2), padding='same', strides=(5,1))(i2)\n",
    "    # (100, 100, c_ch)\n",
    "    \n",
    "    i = concatenate([i1, conv0], axis=3)\n",
    "    # (100, 100, a_ch + b_ch + c_ch)\n",
    "    \n",
    "    conv1 = Conv2D(nf, (6, 6), padding='same', strides=(5,5))(i)\n",
    "    x = LeakyReLU(alpha)(conv1)\n",
    "    # (20, 20, nf)\n",
    "    \n",
    "    conv2 = Conv2D(nf*5, (6, 6), padding='same', strides=(5,5))(x)\n",
    "    x = LeakyReLU(alpha)(conv2)\n",
    "    # (4, 4, nf*5)\n",
    "    \n",
    "    conv3 = Conv2D(1, (3, 3), padding='same', strides=(2,2))(x)\n",
    "    out = Activation('sigmoid')(conv3)\n",
    "    # (2, 2, 1)\n",
    "    \n",
    "    d = Model([i1, i2], out, name=model_name)\n",
    "    \n",
    "    def d_loss(y_true, y_pred):\n",
    "        L = objectives.binary_crossentropy(K.batch_flatten(y_true), K.batch_flatten(y_pred))\n",
    "        return L\n",
    "    \n",
    "    d.compile(optimizer=opt, loss=d_loss)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def full_generator(nf, in_ch=1, out_ch=1, batch_size=1, alpha=0.2, model_name='f_gen'):\n",
    "    a1 = Input(shape=(100, 100, in_ch))\n",
    "    a2 = Input(shape=(100, 100, in_ch))\n",
    "    gen1 = g_unet(nf, 'unet1', in_ch, out_ch, batch_size, alpha)\n",
    "    out1 = gen1(a1)\n",
    "    gen2 = g_unet(nf, 'unet2', in_ch, out_ch, batch_size, alpha)\n",
    "    out2 = gen2(a2)\n",
    "    out = concatenate([out1, out2], axis=1)\n",
    "    f_gen = Model([a1, a2], out, name=model_name)\n",
    "    return f_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pix2pix(atob, d, a_ch=1, b_ch=1, alpha=100, opt=Adam(lr=2e-4, beta_1=0.5), model_name='pix2pix'):\n",
    "    '''\n",
    "    atob - full generator\n",
    "    d - discriminator\n",
    "    '''\n",
    "    a1 = Input(shape=(100, 100, a_ch))\n",
    "    a2 = Input(shape=(100, 100, a_ch))\n",
    "    b = Input(shape=(500, 100, b_ch))\n",
    "    \n",
    "    # генерируем картинку на основе a1 и a2 с помощью объединенного генератора:\n",
    "    bp = atob([a1, a2])\n",
    "    \n",
    "    # дискриминатор получает на вход пару изображений\n",
    "    d_in = [concatenate([a1, a2], axis=3), bp]\n",
    "    pix2pix = Model([a1, a2, b], d(d_in), name=model_name)\n",
    "    \n",
    "    def p2p_loss(y_true, y_pred):\n",
    "        y_true_flat = K.batch_flatten(y_true)\n",
    "        y_pred_flat = K.batch_flatten(y_pred)\n",
    "        \n",
    "        # adversarial loss\n",
    "        L_adv = objectives.binary_crossentropy(y_true_flat, y_pred_flat)\n",
    "        \n",
    "        # atob loss\n",
    "        b_flat = K.batch_flatten(b)\n",
    "        bp_flat = K.batch_flatten(bp)\n",
    "        L_atob = K.mean(K.abs(b_flat - bp_flat))\n",
    "        \n",
    "        return L_adv + alpha*L_atob\n",
    "    \n",
    "    # обучаем генератор - фризим дискриминатор\n",
    "    pix2pix.get_layer('d').trainable = False\n",
    "    \n",
    "    pix2pix.compile(optimizer=opt, loss=p2p_loss)\n",
    "    return pix2pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading + preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# параметры датасета\n",
    "H = 100\n",
    "W = 100\n",
    "W_pan = 500\n",
    "# путь к датасету\n",
    "datasetPath = '../data/sand/trend1'\n",
    "# списки файлов для загрузки\n",
    "trainList = listdir(datasetPath + '/train/panorama')\n",
    "valList = listdir(datasetPath + '/validation/panorama')\n",
    "N_train = len(trainList)\n",
    "N_val = len(valList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "side1Train = np.empty((N_train, W, H, 1))\n",
    "side2Train = np.empty((N_train, W, H, 1))\n",
    "panoramaTrain = np.empty((N_train, W_pan, H, 1))\n",
    "for i, fileName in enumerate(tqdm_notebook(trainList)):\n",
    "    image = Image.open(datasetPath + '/train/side1/' + fileName)\n",
    "    side1Train[i] = np.array(image).T.reshape(W, H, 1)\n",
    "    \n",
    "    image = Image.open(datasetPath + '/train/side2/' + fileName)\n",
    "    side2Train[i] = np.array(image).T.reshape(W, H, 1)\n",
    "    \n",
    "    image = Image.open(datasetPath + '/train/panorama/' + fileName)\n",
    "    panoramaTrain[i] = np.array(image).T.reshape(W_pan, H, 1)\n",
    "print('Train dataset loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "side1Val = np.empty((N_val, W, H, 1))\n",
    "side2Val = np.empty((N_val, W, H, 1))\n",
    "panoramaVal = np.empty((N_val, W_pan, H, 1))\n",
    "for i, fileName in enumerate(tqdm_notebook(valList)):\n",
    "    image = Image.open(datasetPath + '/validation/side1/' + fileName)\n",
    "    side1Val[i] = np.array(image).T.reshape(W, H, 1)\n",
    "    \n",
    "    image = Image.open(datasetPath + '/validation/side2/' + fileName)\n",
    "    side2Val[i] = np.array(image).T.reshape(W, H, 1)\n",
    "    \n",
    "    image = Image.open(datasetPath + '/validation/panorama/' + fileName)\n",
    "    panoramaVal[i] = np.array(image).T.reshape(W_pan, H, 1)\n",
    "print('Validation dataset loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# генераторы изображений\n",
    "side1TrainGen = ImageDataGenerator(rescale=1./255, vertical_flip=True).flow(side1Train, shuffle=True)\n",
    "side2TrainGen = ImageDataGenerator(rescale=1./255, vertical_flip=True).flow(side2Train, shuffle=True)\n",
    "panoramaTrainGen = ImageDataGenerator(rescale=1./255, vertical_flip=True).flow(panoramaTrain, shuffle=True)\n",
    "\n",
    "side1ValGen = ImageDataGenerator(rescale=1./255).flow(side1Val, shuffle=True)\n",
    "side2ValGen = ImageDataGenerator(rescale=1./255).flow(side2Val, shuffle=True)\n",
    "panoramaValGen = ImageDataGenerator(rescale=1./255).flow(panoramaVal, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# генераторы, возвращающие тройки изображений\n",
    "trainGen = zip(side1TrainGen, side2TrainGen, panoramaTrainGen)\n",
    "valGen = zip(side1ValGen, side2ValGen, panoramaValGen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# генератор размеченных данных для обучения дискриминатора\n",
    "def d_generator(dataGen, atob, dout_size):\n",
    "    while True:\n",
    "        # фейковая тройка\n",
    "        a1_fake, a2_fake, _ = next(dataGen)\n",
    "        b_fake = atob.predict([a1_fake, a2_fake])\n",
    "        # реальная тройка\n",
    "        a1_real, a2_real, b_real = next(dataGen)\n",
    "        # объединяем в единый batch\n",
    "        a_fake = np.concatenate((a1_fake, a2_fake), axis=3)\n",
    "        a_real = np.concatenate((a1_real, a2_real), axis=3)\n",
    "        batch_a = np.concatenate((a_fake, a_real), axis=0)\n",
    "        batch_b = np.concatenate((b_fake, b_real), axis=0)\n",
    "        batch_x = [batch_a, batch_b]\n",
    "        # labels: fake - 1, real- 0\n",
    "        batch_y = np.ones((batch_x[0].shape[0], 1) + dout_size)\n",
    "        batch_y[a_fake.shape[0]:] = 0\n",
    "        yield batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# обучение дискриминатора\n",
    "def train_discriminator(d, dataGen, steps_per_batch=20):\n",
    "    return d.fit_generator(dataGen, steps_per_epoch=steps_per_batch*2, epochs=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# генератор данных для сети-генератора\n",
    "def p2p_generator(dataGen, dout_size):\n",
    "    for a1, a2, b in dataGen:\n",
    "        # labels: fake - 1, real- 0\n",
    "        y = np.zeros((a1.shape[0], 1) + dout_size)\n",
    "        yield [a1, a2, b], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# обучение pix2pix-сети\n",
    "def train_p2p(p2p, dataGen, steps_per_batch=20):\n",
    "    return p2p.fit_generator(dataGen, steps_per_epoch=steps_per_batch, epochs=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# вычисление метрик\n",
    "def metrics(dGen, p2pGen, d, p2p, losses, valSamples=200):\n",
    "    dLoss = d.evaluate_generator(dGen, valSamples)\n",
    "    p2pLoss = p2p.evaluate_generator(p2pGen, valSamples)\n",
    "    losses['dVal'].append(dLoss)\n",
    "    losses['p2pVal'].append(p2pLoss)\n",
    "    print ('')\n",
    "    print ('Train Losses of (D={0} / P2P={1});\\n'\n",
    "           'Validation Losses of (D={2} / P2P={3})'.format(\n",
    "                losses['d'][-1], losses['p2p'][-1], d_loss, p2p_loss))\n",
    "    return dLoss, p2pLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# итерация обучения\n",
    "def train_iteration(d, p2p, dGen, p2pGen, losses):\n",
    "    # дискриминатор\n",
    "    dHist = train_discriminator(d, dGen)\n",
    "    losses['d'].extend(dHist.history['loss'])\n",
    "    # генератор\n",
    "    p2pHist = train_p2p(p2p, p2pGen)\n",
    "    losses['p2p'].extend(p2pHist.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# обучение\n",
    "def train(atob, d, p2p, trainGen, valGen, epochs, trainSamples, samplesPerBatch):\n",
    "    # создаем необходимые генераторы\n",
    "    dout_size = d.output_shape[1:3]\n",
    "    dGenTrain = d_generator(trainGen, atob, dout_size)\n",
    "    # для работы tensorflow\n",
    "    next(dGenTrain)\n",
    "    dGenVal = d_generator(valGen, atob, dout_size)\n",
    "    p2pGenTrain = p2p_generator(trainGen, dout_size)\n",
    "    p2pGenVal = p2p_generator(valGen, dout_size)\n",
    "    losses = {'p2p': [], 'd': [], 'p2p_val': [], 'd_val': []}\n",
    "    batchesPerEpoch = trainSamples // samplesPerBatch\n",
    "    # цикл обучения \n",
    "    for e in tnrange(epochs, desc='Epoches'):\n",
    "        for b in tnrange(batchesPerEpoch, desc='Batches', leave=False):\n",
    "            train_iteration(d, p2p, dGenTrain, p2pGenTrain, losses)\n",
    "        # вычисляем метрики на валидации\n",
    "        metrics(dValGen, p2pValGen, d, p2p, losses, N_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# создание моделей\n",
    "f_gen = full_generator(5)\n",
    "d = discriminator(5)\n",
    "p2p = pix2pix(f_gen, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-8630da7af320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# обучение\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainGen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalGen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-4a7d5c6c58ef>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(atob, d, p2p, trainGen, valGen, epochs, trainSamples, samplesPerBatch)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Epoches'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchesPerEpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Batches'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mtrain_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdGenTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2pGenTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# вычисляем метрики на валидации\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdValGen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2pValGen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-9257892328b1>\u001b[0m in \u001b[0;36mtrain_iteration\u001b[0;34m(d, p2p, dGen, p2pGen, losses)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdGen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2pGen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# дискриминатор\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdHist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdGen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdHist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# генератор\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-346e6768c77c>\u001b[0m in \u001b[0;36mtrain_discriminator\u001b[0;34m(d, dataGen, steps_per_batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# обучение дискриминатора\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataGen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataGen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_batch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ysbudakyan/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlegacy_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ysbudakyan/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1875\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ysbudakyan/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ysbudakyan/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2075\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2076\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ysbudakyan/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ysbudakyan/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ysbudakyan/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ysbudakyan/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ysbudakyan/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# обучение\n",
    "train(f_gen, d, p2p, trainGen, valGen, 5, N_train, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3326ff9828>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using trained NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-38b001184f06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trange' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "52a40718da484e83810962595a47a3e4": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "7c8a2706b3be4aca8017c15d6414d318": {
     "views": [
      {
       "cell_index": 24
      }
     ]
    },
    "b9e28426444242e0aefbae24aa5c0ce3": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "d48c46bd6e1248cc930544c1260cc2be": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
