{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pix2pix(U-Net + GAN) experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import objectives\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose, Cropping2D\n",
    "from keras.layers.core import Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# U-Net Generator\n",
    "def g_unet(nf, model_name, in_ch=1, out_ch=1, batch_size=1, alpha=0.2):\n",
    "    ''' параметры:\n",
    "    input shape = (100, 100, in_ch)\n",
    "    output = (100, 250, out_ch)\n",
    "    nf - число фильтров на входном слое\n",
    "    alpha - параметр LeakyReLU\n",
    "    '''\n",
    "    i = Input(shape=(100, 100, in_ch))\n",
    "    # (100, 100, in_ch)\n",
    "    \n",
    "    conv1 = Conv2D(nf, (6, 6), padding='same', strides=(5, 5))(i)\n",
    "    conv1 = BatchNormalization(axis=3)(conv1)\n",
    "    x = LeakyReLU(alpha)(conv1)\n",
    "    # (20, 20, nf)\n",
    "    \n",
    "    conv2 = Conv2D(nf*5, (6, 6), padding='same', strides=(5, 5))(x)\n",
    "    conv2 = BatchNormalization(axis=3)(conv2)\n",
    "    x = LeakyReLU(alpha)(conv2)\n",
    "    # (4, 4, nf*5)\n",
    "    \n",
    "    conv3 = Conv2D(nf*10, (3, 3), padding='same', strides=(2, 2))(x)\n",
    "    conv3 = BatchNormalization(axis=3)(conv3)\n",
    "    x = LeakyReLU(alpha)(conv3)\n",
    "    # (2, 2, nf*10)\n",
    "\n",
    "    conv4 = Conv2D(nf*10, (2, 2), padding='valid', strides=(1, 1))(x)\n",
    "    conv4 = BatchNormalization(axis=3)(conv4)\n",
    "    x = LeakyReLU(alpha)(conv4)\n",
    "    # (1, 1, nf*10)\n",
    "\n",
    "    dconv1 = Conv2DTranspose(nf*10, (2, 2), strides=(1, 1))(x)\n",
    "    dconv1 = BatchNormalization(axis=3)(dconv1)\n",
    "    dconv1 = Dropout(0.5)(dconv1)\n",
    "    x = concatenate([dconv1, conv3], axis=3)\n",
    "    x = LeakyReLU(alpha)(x)\n",
    "    # (2, 2, nf*(10 + 10))\n",
    "\n",
    "    dconv2 = Conv2DTranspose(nf*5, (2, 2), strides=(2, 2))(x)\n",
    "    dconv2 = BatchNormalization(axis=3)(dconv2)\n",
    "    x = concatenate([dconv2, conv2], axis=3)\n",
    "    x = LeakyReLU(alpha)(x)\n",
    "    # (4, 4, nf*(5 + 5))\n",
    "\n",
    "    dconv3 = Conv2DTranspose(nf, (2, 2), strides=(5, 5))(x)\n",
    "    dconv3 = BatchNormalization(axis=3)(dconv3)\n",
    "    x = concatenate([dconv3, conv1], axis=3)\n",
    "    x = LeakyReLU(alpha)(x)\n",
    "    # (20, 20, nf*(1 + 1))\n",
    "\n",
    "    dconv4 = Conv2DTranspose(out_ch, (2, 2), strides=(13, 5))(x)\n",
    "    # (260, 100, out_ch)\n",
    "    \n",
    "    dconv4 = Cropping2D((5, 0))(dconv4)\n",
    "    # (250, 100, out_ch)\n",
    "\n",
    "    out = Activation('tanh')(dconv4)\n",
    "    unet = Model(i, out, name=model_name)\n",
    "    \n",
    "    return unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "def discriminator(nf, a_ch=1, b_ch=1, c_ch=1, opt=Adam(lr=2e-4, beta_1=0.5), alpha=0.2, model_name='d'):\n",
    "    ''' параметры:\n",
    "    a_ch - число каналов первого изображения\n",
    "    b_ch - число каналов второго\n",
    "    c_ch - третьего\n",
    "    nf - число фильтров на входном слое\n",
    "    alpha - параметр LeakyReLU\n",
    "    '''\n",
    "    i1 = Input(shape=(100, 100, a_ch + b_ch))\n",
    "    # (100, 100, a_ch + b_ch) - side1 + side2\n",
    "    \n",
    "    i2 = Input(shape=(500, 100, c_ch))\n",
    "    # (500, 100, c_ch) - panorama\n",
    "    \n",
    "    conv0 = Conv2D(c_ch, (6,2), padding='same', strides=(5,1))(i2)\n",
    "    # (100, 100, c_ch)\n",
    "    \n",
    "    i = concatenate([i1, conv0], axis=3)\n",
    "    # (100, 100, a_ch + b_ch + c_ch)\n",
    "    \n",
    "    conv1 = Conv2D(nf, (6, 6), padding='same', strides=(5,5))(i)\n",
    "    x = LeakyReLU(alpha)(conv1)\n",
    "    # (20, 20, nf)\n",
    "    \n",
    "    conv2 = Conv2D(nf*5, (6, 6), padding='same', strides=(5,5))(x)\n",
    "    x = LeakyReLU(alpha)(conv2)\n",
    "    # (4, 4, nf*5)\n",
    "    \n",
    "    conv3 = Conv2D(1, (3, 3), padding='same', strides=(2,2))(x)\n",
    "    out = Activation('sigmoid')(conv3)\n",
    "    # (2, 2, 1)\n",
    "    \n",
    "    d = Model([i1, i2], out, name=model_name)\n",
    "    \n",
    "    def d_loss(y_true, y_pred):\n",
    "        L = objectives.binary_crossentropy(K.batch_flatten(y_true), K.batch_flatten(y_pred))\n",
    "        return L\n",
    "    \n",
    "    d.compile(optimizer=opt, loss=d_loss)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputd = d.predict(batch_x)\n",
    "batch_y = np.ones((batch_x[0].shape[0], 1) + d.output_shape[-2:], dtype=np.float32)\n",
    "batch_y[a_fake.shape[0]:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float32'> <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print(type(batch_y[0][0][0][0]), type(outputd[0][0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'> <class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "flatY = K.batch_flatten(batch_y)\n",
    "flatP = K.batch_flatten(outputd)\n",
    "print(type(flatY), type(flatP))\n",
    "L = objectives.binary_crossentropy(flatY, flatP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_26:0' shape=(?,) dtype=float32>"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def full_generator(nf, in_ch=1, out_ch=1, batch_size=1, alpha=0.2, model_name='f_gen'):\n",
    "    a1 = Input(shape=(100, 100, in_ch))\n",
    "    a2 = Input(shape=(100, 100, in_ch))\n",
    "    gen1 = g_unet(nf, 'unet1', in_ch, out_ch, batch_size, alpha)\n",
    "    out1 = gen1(a1)\n",
    "    gen2 = g_unet(nf, 'unet2', in_ch, out_ch, batch_size, alpha)\n",
    "    out2 = gen2(a2)\n",
    "    out = concatenate([out1, out2], axis=1)\n",
    "    f_gen = Model([a1, a2], out, name=model_name)\n",
    "    return f_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pix2pix(atob, d, a_ch=1, b_ch=1, alpha=100, opt=Adam(lr=2e-4, beta_1=0.5), model_name='pix2pix'):\n",
    "    '''\n",
    "    atob - full generator\n",
    "    d - discriminator\n",
    "    '''\n",
    "    a1 = Input(shape=(100, 100, a_ch))\n",
    "    a2 = Input(shape=(100, 100, a_ch))\n",
    "    b = Input(shape=(500, 100, b_ch))\n",
    "    \n",
    "    # генерируем картинку на основе a1 и a2 с помощью объединенного генератора:\n",
    "    bp = atob([a1, a2])\n",
    "    \n",
    "    # дискриминатор получает на вход пару изображений\n",
    "    d_in = [concatenate([a1, a2], axis=3), bp]\n",
    "    pix2pix = Model([a1, a2, b], d(d_in), name=model_name)\n",
    "    \n",
    "    def p2p_loss(y_true, y_pred):\n",
    "        y_true_flat = K.batch_flatten(y_true)\n",
    "        y_pred_flat = K.batch_flatten(y_pred)\n",
    "        \n",
    "        # adversarial loss\n",
    "        L_adv = objectives.binary_crossentropy(y_true_flat, y_pred_flat)\n",
    "        \n",
    "        # atob loss\n",
    "        b_flat = K.batch_flatten(b)\n",
    "        bp_flat = K.batch_flatten(bp)\n",
    "        L_atob = K.mean(K.abs(b_flat - bp_flat))\n",
    "        \n",
    "        return L_adv + alpha*L_atob\n",
    "    \n",
    "    # обучаем генератор - фризим дискриминатор\n",
    "    pix2pix.get_layer('d').trainable = False\n",
    "    \n",
    "    pix2pix.compile(optimizer=opt, loss=p2p_loss)\n",
    "    return pix2pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading + preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# параметры датасета\n",
    "H = 100\n",
    "W = 100\n",
    "W_pan = 500\n",
    "# путь к датасету\n",
    "datasetPath = '../data/sand/trend1'\n",
    "# списки файлов для загрузки\n",
    "trainList = listdir(datasetPath + '/train/panorama')\n",
    "valList = listdir(datasetPath + '/validation/panorama')\n",
    "N_train = len(trainList)\n",
    "N_val = len(valList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:02<00:00, 394.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "side1Train = np.empty((N_train, W, H, 1))\n",
    "side2Train = np.empty((N_train, W, H, 1))\n",
    "panoramaTrain = np.empty((N_train, W_pan, H, 1))\n",
    "for i, fileName in enumerate(tqdm(trainList)):\n",
    "    image = Image.open(datasetPath + '/train/side1/' + fileName)\n",
    "    side1Train[i] = np.array(image).T.reshape(W, H, 1)\n",
    "    \n",
    "    image = Image.open(datasetPath + '/train/side2/' + fileName)\n",
    "    side2Train[i] = np.array(image).T.reshape(W, H, 1)\n",
    "    \n",
    "    image = Image.open(datasetPath + '/train/panorama/' + fileName)\n",
    "    panoramaTrain[i] = np.array(image).T.reshape(W_pan, H, 1)\n",
    "print('Train dataset loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 363.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dataset loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "side1Val = np.empty((N_val, W, H, 1))\n",
    "side2Val = np.empty((N_val, W, H, 1))\n",
    "panoramaVal = np.empty((N_val, W_pan, H, 1))\n",
    "for i, fileName in enumerate(tqdm(valList)):\n",
    "    image = Image.open(datasetPath + '/validation/side1/' + fileName)\n",
    "    side1Val[i] = np.array(image).T.reshape(W, H, 1)\n",
    "    \n",
    "    image = Image.open(datasetPath + '/validation/side2/' + fileName)\n",
    "    side2Val[i] = np.array(image).T.reshape(W, H, 1)\n",
    "    \n",
    "    image = Image.open(datasetPath + '/validation/panorama/' + fileName)\n",
    "    panoramaVal[i] = np.array(image).T.reshape(W_pan, H, 1)\n",
    "print('Validation dataset loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# генераторы изображений\n",
    "side1TrainGen = ImageDataGenerator(rescale=1./255, vertical_flip=True).flow(side1Train, shuffle=True)\n",
    "side2TrainGen = ImageDataGenerator(rescale=1./255, vertical_flip=True).flow(side2Train, shuffle=True)\n",
    "panoramaTrainGen = ImageDataGenerator(rescale=1./255, vertical_flip=True).flow(panoramaTrain, shuffle=True)\n",
    "\n",
    "side1ValGen = ImageDataGenerator(rescale=1./255).flow(side1Val, shuffle=True)\n",
    "side2ValGen = ImageDataGenerator(rescale=1./255).flow(side2Val, shuffle=True)\n",
    "panoramaValGen = ImageDataGenerator(rescale=1./255).flow(panoramaVal, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# генераторы, возвращающие тройки изображений\n",
    "trainGen = zip(side1TrainGen, side2TrainGen, panoramaTrainGen)\n",
    "valGen = zip(side1ValGen, side2ValGen, panoramaValGen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# генератор размеченных данных для обучения дискриминатора\n",
    "def d_generator(dataGen, atob, dout_size):\n",
    "    while True:\n",
    "        # фейковая тройка\n",
    "        a1_fake, a2_fake, _ = next(dataGen)\n",
    "        b_fake = atob.predict([a1_fake, a2_fake])\n",
    "        # реальная тройка\n",
    "        a1_real, a2_real, b_real = next(dataGen)\n",
    "        # объединяем в единый batch\n",
    "        a_fake = np.concatenate((a1_fake, a2_fake), axis=3)\n",
    "        a_real = np.concatenate((a1_real, a2_real), axis=3)\n",
    "        batch_a = np.concatenate((a_fake, a_real), axis=0)\n",
    "        batch_b = np.concatenate((b_fake, b_real), axis=0)\n",
    "        batch_x = [batch_a, batch_b]\n",
    "        # labels: fake - 1, real- 0\n",
    "        batch_y = np.ones((batch_x[0].shape[0], 1) + dout_size)\n",
    "        batch_y[a_fake.shape[0]:] = 0\n",
    "        yield batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# обучение дискриминатора\n",
    "def train_discriminator(d, dataGen, steps_per_batch=20):\n",
    "    return d.fit_generator(dataGen, steps_per_epoch=steps_per_batch*2, epochs=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# генератор данных для сети-генератора\n",
    "def p2p_generator(dataGen, dout_size):\n",
    "    for a1, a2, b in dataGen:\n",
    "        # labels: fake - 1, real- 0\n",
    "        y = np.zeros((a1.shape[0], 1) + dout_size)\n",
    "        yield [a1, a2, b], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# обучение pix2pix-сети\n",
    "def train_p2p(p2p, dataGen, steps_per_batch=20):\n",
    "    return p2p.fit_generator(dataGen, steps_per_epoch=steps_per_batch, epochs=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# создание моделей\n",
    "f_gen = full_generator(5)\n",
    "d = discriminator(5)\n",
    "p2p = pix2pix(f_gen, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_gen = d_generator(trainGen, f_gen, d.output_shape[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p2p_gen = p2p_generator(trainGen, d.output_shape[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3326ff9828>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p2p(p2p, p2p_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using trained NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
