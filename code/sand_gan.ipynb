{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pix2pix(U-Net + GAN) experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import objectives\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose, Cropping2D\n",
    "from keras.layers.core import Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# U-Net Generator\n",
    "def g_unet(nf, model_name, in_ch=1, out_ch=1, batch_size=1, alpha=0.2):\n",
    "    ''' параметры:\n",
    "    input shape = (100, 100, in_ch)\n",
    "    output = (100, 250, out_ch)\n",
    "    nf - число фильтров на входном слое\n",
    "    alpha - параметр LeakyReLU\n",
    "    '''\n",
    "    i = Input(shape=(100, 100, in_ch))\n",
    "    # (100, 100, in_ch)\n",
    "    \n",
    "    conv1 = Conv2D(nf, (6, 6), padding='same', strides=(5, 5))(i)\n",
    "    conv1 = BatchNormalization(axis=3)(conv1)\n",
    "    x = LeakyReLU(alpha)(conv1)\n",
    "    # (20, 20, nf)\n",
    "    \n",
    "    conv2 = Conv2D(nf*5, (6, 6), padding='same', strides=(5, 5))(x)\n",
    "    conv2 = BatchNormalization(axis=3)(conv2)\n",
    "    x = LeakyReLU(alpha)(conv2)\n",
    "    # (4, 4, nf*5)\n",
    "    \n",
    "    conv3 = Conv2D(nf*10, (3, 3), padding='same', strides=(2, 2))(x)\n",
    "    conv3 = BatchNormalization(axis=3)(conv3)\n",
    "    x = LeakyReLU(alpha)(conv3)\n",
    "    # (2, 2, nf*10)\n",
    "\n",
    "    conv4 = Conv2D(nf*10, (2, 2), padding='valid', strides=(1, 1))(x)\n",
    "    conv4 = BatchNormalization(axis=3)(conv4)\n",
    "    x = LeakyReLU(alpha)(conv4)\n",
    "    # (1, 1, nf*10)\n",
    "\n",
    "    dconv1 = Conv2DTranspose(nf*10, (2, 2), strides=(1, 1))(x)\n",
    "    dconv1 = BatchNormalization(axis=3)(dconv1)\n",
    "    dconv1 = Dropout(0.5)(dconv1)\n",
    "    x = concatenate([dconv1, conv3], axis=3)\n",
    "    x = LeakyReLU(alpha)(x)\n",
    "    # (2, 2, nf*(10 + 10))\n",
    "\n",
    "    dconv2 = Conv2DTranspose(nf*5, (2, 2), strides=(2, 2))(x)\n",
    "    dconv2 = BatchNormalization(axis=3)(dconv2)\n",
    "    x = concatenate([dconv2, conv2], axis=3)\n",
    "    x = LeakyReLU(alpha)(x)\n",
    "    # (4, 4, nf*(5 + 5))\n",
    "\n",
    "    dconv3 = Conv2DTranspose(nf, (2, 2), strides=(5, 5))(x)\n",
    "    dconv3 = BatchNormalization(axis=3)(dconv3)\n",
    "    x = concatenate([dconv3, conv1], axis=3)\n",
    "    x = LeakyReLU(alpha)(x)\n",
    "    # (20, 20, nf*(1 + 1))\n",
    "\n",
    "    dconv4 = Conv2DTranspose(out_ch, (2, 2), strides=(13, 5))(x)\n",
    "    # (260, 100, out_ch)\n",
    "    \n",
    "    dconv4 = Cropping2D((5, 0))(dconv4)\n",
    "    # (250, 100, out_ch)\n",
    "\n",
    "    out = Activation('tanh')(dconv4)\n",
    "    unet = Model(i, out, name=model_name)\n",
    "    \n",
    "    return unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "def discriminator(nf, a_ch=1, b_ch=1, opt=Adam(lr=2e-4, beta_1=0.5), alpha=0.2, model_name='d'):\n",
    "    ''' параметры:\n",
    "    a_ch - число каналов первого изображения\n",
    "    b_ch - число каналов второго\n",
    "    nf - число фильтров на входном слое\n",
    "    alpha - параметр LeakyReLU\n",
    "    '''\n",
    "    i = Input(shape=(500, 100, a_ch + b_ch))\n",
    "    # (500, 100, a_ch + b_ch)\n",
    "    \n",
    "    conv1 = Conv2D(nf, (6, 6), padding='same', strides=(5,5))(i)\n",
    "    x = LeakyReLU(alpha)(conv1)\n",
    "    # (100, 20, nf)\n",
    "    \n",
    "    conv2 = Conv2D(nf*5, (6, 6), padding='same', strides=(5,5))(x)\n",
    "    x = LeakyReLU(alpha)(conv2)\n",
    "    # (20, 4, nf*5)\n",
    "    \n",
    "    conv3 = Conv2D(1, (3, 3), padding='same', strides=(2,2))(x)\n",
    "    out = Activation('sigmoid')(conv3)\n",
    "    # (10, 2, 1)\n",
    "    \n",
    "    d = Model(i, out, name=model_name)\n",
    "    \n",
    "    def d_loss(y_true, y_pred):\n",
    "        L = objectives.binary_crossentropy(K.batch_flatten(y_true), K.batch_flatten(y_pred))\n",
    "        return L\n",
    "    \n",
    "    d.compile(optimizer=opt, loss=d_loss)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def full_generator(nf, in_ch=1, out_ch=1, batch_size=1, alpha=0.2, model_name='f_gen'):\n",
    "    a1 = Input(shape=(100, 100, in_ch))\n",
    "    a2 = Input(shape=(100, 100, in_ch))\n",
    "    gen1 = g_unet(nf, 'unet1', in_ch, out_ch, batch_size, alpha)\n",
    "    out1 = gen1(a1)\n",
    "    gen2 = g_unet(nf, 'unet2', in_ch, out_ch, batch_size, alpha)\n",
    "    out2 = gen2(a2)\n",
    "    out = concatenate([out1, out2], axis=1)\n",
    "    f_gen = Model([a1, a2], out, name=model_name)\n",
    "    return f_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pix2pix(atob, d, a_ch=1, b_ch=1, alpha=100, opt=Adam(lr=2e-4, beta_1=0.5), model_name='pix2pix'):\n",
    "    '''\n",
    "    atob - full generator\n",
    "    d - discriminator\n",
    "    '''\n",
    "    a1 = Input(shape=(100, 100, a_ch))\n",
    "    a2 = Input(shape=(100, 100, a_ch))\n",
    "    b = Input(shape=(500, 100, b_ch))\n",
    "    \n",
    "    # генерируем картинку на основе a1 и a2 с помощью объединенного генератора:\n",
    "    bp = atob([a1, a2])\n",
    "    \n",
    "    # дискриминатор получает на вход пару изображений\n",
    "    d_in = concatenate([b, bp], axis=3)\n",
    "    pix2pix = Model([a1, a2, b], d(d_in), name=model_name)\n",
    "    \n",
    "    def p2p_loss(y_true, y_pred):\n",
    "        y_true_flat = K.batch_flatten(y_true)\n",
    "        y_pred_flat = K.batch_flatten(y_pred)\n",
    "        \n",
    "        # adversarial loss\n",
    "        L_adv = objectives.binary_crossentropy(y_true_flat, y_pred_flat)\n",
    "        \n",
    "        # atob loss\n",
    "        b_flat = K.batch_flatten(b)\n",
    "        bp_flat = K.batch_flatten(bp)\n",
    "        L_atob = K.mean(K.abs(b_flat - bp_flat))\n",
    "        \n",
    "        return L_adv + alpha*L_atob\n",
    "    \n",
    "    # обучаем генератор - фризим дискриминатор\n",
    "    pix2pix.get_layer('d').trainable = False\n",
    "    \n",
    "    pix2pix.compile(optimizer=opt, loss=p2p_loss)\n",
    "    return pix2pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading + preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = 100\n",
    "W = 500\n",
    "dataPrefix = '../data/sand/full_dataset/trend1/panorama/sample'\n",
    "dataExt = '.jpg'\n",
    "\n",
    "def loadImage(i):\n",
    "    fileName = dataPrefix + str(i) + dataExt\n",
    "    im = Image.open(fileName)\n",
    "    return np.array(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = loadImage(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = im.reshape(1, 100, 100, 1)\n",
    "y = np.array([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_gen = full_generator(5)\n",
    "d = discriminator(5)\n",
    "p2p = pix2pix(f_gen, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_110 (InputLayer)           (None, 100, 100, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_111 (InputLayer)           (None, 100, 100, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "unet1 (Model)                    (None, 250, 100, 1)   48021                                        \n",
      "____________________________________________________________________________________________________\n",
      "unet2 (Model)                    (None, 250, 100, 1)   48021                                        \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)     (None, 500, 100, 1)   0                                            \n",
      "====================================================================================================\n",
      "Total params: 96,042.0\n",
      "Trainable params: 95,202.0\n",
      "Non-trainable params: 840.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f_gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 10, 2, 1)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_115 (InputLayer)           (None, 100, 100, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_116 (InputLayer)           (None, 100, 100, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_117 (InputLayer)           (None, 500, 100, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "f_gen (Model)                    (None, 500, 100, 1)   96042                                        \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)     (None, 500, 100, 2)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "d (Model)                        (None, 10, 2, 1)      5116                                         \n",
      "====================================================================================================\n",
      "Total params: 101,158.0\n",
      "Trainable params: 100,318.0\n",
      "Non-trainable params: 840.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "p2p.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using trained NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x7f8372f5c860>,\n",
       " <keras.engine.topology.InputLayer at 0x7f83729e39e8>,\n",
       " <keras.engine.topology.InputLayer at 0x7f83729e39b0>,\n",
       " <keras.engine.training.Model at 0x7f8373075b70>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8371ec9f98>,\n",
       " <keras.engine.training.Model at 0x7f8372a61da0>]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2p.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 500, 100, 1)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_gen.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 500, 100, 2)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 10, 2, 1)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
