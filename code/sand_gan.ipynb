{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pix2pix(U-Net + GAN) experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import objectives\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Merge, merge\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution2D, Deconvolution2D\n",
    "from keras.layers.core import Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# U-Net Generator\n",
    "def g_unet(nf, model_name, in_ch=1, out_ch=1, batch_size=1, alpha=0.2):\n",
    "    ''' параметры:\n",
    "    input shape = (100, 100, in_ch)\n",
    "    output = (100, 250, out_ch)\n",
    "    nf - число фильтров на входном слое\n",
    "    alpha - параметр LeakyReLU\n",
    "    '''\n",
    "    i = Input(shape=(100, 100, in_ch))\n",
    "    # (100, 100, in_ch)\n",
    "    \n",
    "    conv1 = Convolution2D(nf, 6, 6, border_mode='same', subsample=(5, 5))(i)\n",
    "    conv1 = BatchNormalization(mode=2, axis=1)(conv1)\n",
    "    x = LeakyReLU(alpha)(conv1)\n",
    "    # (20, 20, nf)\n",
    "    \n",
    "    conv2 = Convolution2D(nf*5, 6, 6, border_mode='same', subsample=(5, 5))(x)\n",
    "    conv2 = BatchNormalization(mode=2, axis=1)(conv2)\n",
    "    x = LeakyReLU(alpha)(conv2)\n",
    "    # (4, 4, nf*5)\n",
    "    \n",
    "    conv3 = Convolution2D(nf*10, 3, 3, border_mode='same', subsample=(2, 2))(x)\n",
    "    conv3 = BatchNormalization(mode=2, axis=1)(conv3)\n",
    "    x = LeakyReLU(alpha)(conv3)\n",
    "    # (2, 2, nf*10)\n",
    "\n",
    "    conv4 = Convolution2D(nf*10, 2, 2, border_mode='valid', subsample=(1, 1))(x)\n",
    "    conv4 = BatchNormalization(mode=2, axis=1)(conv4)\n",
    "    x = LeakyReLU(alpha)(conv4)\n",
    "    # (1, 1, nf*10)\n",
    "\n",
    "    dconv1 = Deconvolution2D(nf*10, 2, 2, output_shape=(batch_size, 2, 2, nf*10), subsample=(1, 1))(x)\n",
    "    dconv1 = BatchNormalization(mode=2, axis=1)(dconv1)\n",
    "    dconv1 = Dropout(0.5)(dconv1)\n",
    "    x = merge([dconv1, conv3], mode='concat', concat_axis=3)\n",
    "    x = LeakyReLU(alpha)(x)\n",
    "    # (2, 2, nf*(10 + 10))\n",
    "\n",
    "    dconv2 = Deconvolution2D(nf*5, 2, 2, output_shape=(batch_size, 4, 4, nf*5), subsample=(2, 2))(x)\n",
    "    dconv2 = BatchNormalization(mode=2, axis=1)(dconv2)\n",
    "    x = merge([dconv2, conv2], mode='concat', concat_axis=3)\n",
    "    x = LeakyReLU(alpha)(x)\n",
    "    # (4, 4, nf*(5 + 5))\n",
    "\n",
    "    dconv3 = Deconvolution2D(nf, 2, 2, output_shape=(batch_size, 20, 20, nf), subsample=(2, 2))(x)\n",
    "    dconv3 = BatchNormalization(mode=2, axis=1)(dconv3)\n",
    "    x = merge([dconv3, conv1], mode='concat', concat_axis=3)\n",
    "    x = LeakyReLU(alpha)(x)\n",
    "    # (20, 20, nf*(1 + 1))\n",
    "\n",
    "    dconv4 = Deconvolution2D(1, 2, 2, output_shape=(batch_size, 250, 100, out_ch))(x)\n",
    "    # (250, 100, out_ch)\n",
    "\n",
    "    out = Activation('tanh')(dconv4)\n",
    "    unet = Model(i, out, name=model_name)\n",
    "    \n",
    "    return unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "def discriminator(nf, a_ch=1, b_ch=1, opt=Adam(lr=2e-4, beta_1=0.5), alpha=0.2, model_name='d'):\n",
    "    ''' параметры:\n",
    "    a_ch - число каналов первого изображения\n",
    "    b_ch - число каналов второго\n",
    "    nf - число фильтров на входном слое\n",
    "    alpha - параметр LeakyReLU\n",
    "    '''\n",
    "    i = Input(shape=(500, 100, a_ch + b_ch))\n",
    "    # (500, 100, a_ch + b_ch)\n",
    "    \n",
    "    conv1 = Convolution2D(nf, 6, 6, border_mode='same', subsample=(5,5))(i)\n",
    "    x = LeakyReLU(alpha)(conv1)\n",
    "    # (100, 20, nf)\n",
    "    \n",
    "    conv2 = Convolution2D(nf*5, 6, 6, border_mode='same', subsample=(5,5))(x)\n",
    "    x = LeakyReLU(alpha)(conv2)\n",
    "    # (20, 4, nf*5)\n",
    "    \n",
    "    conv3 = Convolution2D(1, 3, 3, border_mode='same', subsample=(2,2))(x)\n",
    "    out = Activation('sigmoid')(conv3)\n",
    "    # (10, 2, 1)\n",
    "    \n",
    "    d = Model(i, out, name=model_name)\n",
    "    \n",
    "    def d_loss(y_true, y_pred):\n",
    "        L = objectives.binary_crossentropy(K.batch_flatten(y_true), K.batch_flatten(y_pred))\n",
    "        return L\n",
    "    \n",
    "    d.compile(optimizer=opt, loss=d_loss)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def full_generator(nf, in_ch=1, out_ch=1, batch_size=1, alpha=0.2, model_name='f_gen'):\n",
    "    a1 = Input(shape=(100, 100, in_ch))\n",
    "    a2 = Input(shape=(100, 100, in_ch))\n",
    "    gen1 = g_unet(nf, 'unet1', in_ch, out_ch, batch_size, alpha)\n",
    "    out1 = gen1(a1)\n",
    "    gen2 = g_unet(nf, 'unet2', in_ch, out_ch, batch_size, alpha)\n",
    "    out2 = gen2(a2)\n",
    "    out = merge([out1, out2], mode='concat', concat_axis=1)\n",
    "    f_gen = Model([a1, a2], out, name=model_name)\n",
    "    return f_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pix2pix(atob, d, a_ch=1, b_ch=1, alpha=100, opt=Adam(lr=2e-4, beta_1=0.5), model_name='pix2pix'):\n",
    "    '''\n",
    "    atob - full generator\n",
    "    d - discriminator\n",
    "    '''\n",
    "    a1 = Input(shape=(100, 100, a_ch))\n",
    "    a2 = Input(shape=(100, 100, a_ch))\n",
    "    b = Input(shape=(500, 100, b_ch))\n",
    "    \n",
    "    # генерируем картинку на основе a1 и a2 с помощью объединенного генератора:\n",
    "    bp = atob([a1, a2])\n",
    "    \n",
    "    # дискриминатор получает на вход пару изображений\n",
    "    d_in = merge([b, bp], mode='concat', concat_axis=3)\n",
    "    pix2pix = Model([a1, a2, b], d(d_in), name=model_name)\n",
    "    \n",
    "    def p2p_loss(y_true, y_pred):\n",
    "        y_true_flat = K.batch_flatten(y_true)\n",
    "        y_pred_flat = K.batch_flatten(y_pred)\n",
    "        \n",
    "        # adversarial loss\n",
    "        L_adv = objectives.binary_crossentropy(y_true_flat, y_pred_flat)\n",
    "        \n",
    "        # atob loss\n",
    "        b_flat = K.batch_flatten(b)\n",
    "        bp_flat = K.batch_flatten(bp)\n",
    "        L_atob = K.mean(K.abs(b_flat - bp_flat))\n",
    "        \n",
    "        return L_adv + alpha*L_atob\n",
    "    \n",
    "    # обучаем генератор - фризим дискриминатор\n",
    "    pix2pix.get_layer('d').trainable = False\n",
    "    \n",
    "    pix2pix.compile(optimizer=opt, loss=p2p_loss)\n",
    "    return pix2pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading + preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = 100\n",
    "W = 500\n",
    "dataPrefix = '../data/sand/full_dataset/trend1/panorama/sample'\n",
    "dataExt = '.jpg'\n",
    "\n",
    "def loadImage(i):\n",
    "    fileName = dataPrefix + str(i) + dataExt\n",
    "    im = Image.open(fileName)\n",
    "    return np.array(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = loadImage(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = im.reshape(1, 100, 100, 1)\n",
    "y = np.array([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_gen = full_generator(5)\n",
    "d = discriminator(5)\n",
    "p2p = pix2pix(f_gen, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_6 (InputLayer)             (None, 100, 100, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 20, 20, 5)     185                                          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_15 (BatchNorm (None, 20, 20, 5)     80                                           \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_18 (LeakyReLU)         (None, 20, 20, 5)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 4, 4, 25)      4525                                         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_16 (BatchNorm (None, 4, 4, 25)      16                                           \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_19 (LeakyReLU)         (None, 4, 4, 25)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 2, 2, 50)      11300                                        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_17 (BatchNorm (None, 2, 2, 50)      8                                            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_20 (LeakyReLU)         (None, 2, 2, 50)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 1, 1, 50)      10050                                        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_18 (BatchNorm (None, 1, 1, 50)      4                                            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_21 (LeakyReLU)         (None, 1, 1, 50)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconvolution2d_9 (Deconvolution (None, 2, 2, 50)      10050                                        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_19 (BatchNorm (None, 2, 2, 50)      8                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 2, 2, 50)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_9 (Merge)                  (None, 2, 2, 100)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_22 (LeakyReLU)         (None, 2, 2, 100)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconvolution2d_10 (Deconvolutio (None, 4, 4, 25)      10025                                        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_20 (BatchNorm (None, 4, 4, 25)      16                                           \n",
      "____________________________________________________________________________________________________\n",
      "merge_10 (Merge)                 (None, 4, 4, 50)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_23 (LeakyReLU)         (None, 4, 4, 50)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconvolution2d_11 (Deconvolutio (None, 20, 20, 5)     1005                                         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_21 (BatchNorm (None, 20, 20, 5)     80                                           \n",
      "____________________________________________________________________________________________________\n",
      "merge_11 (Merge)                 (None, 20, 20, 10)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_24 (LeakyReLU)         (None, 20, 20, 10)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconvolution2d_12 (Deconvolutio (None, 250, 100, 1)   41                                           \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 250, 100, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_7 (InputLayer)             (None, 100, 100, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 20, 20, 5)     185                                          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_22 (BatchNorm (None, 20, 20, 5)     80                                           \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_25 (LeakyReLU)         (None, 20, 20, 5)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 4, 4, 25)      4525                                         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_23 (BatchNorm (None, 4, 4, 25)      16                                           \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_26 (LeakyReLU)         (None, 4, 4, 25)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 2, 2, 50)      11300                                        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_24 (BatchNorm (None, 2, 2, 50)      8                                            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_27 (LeakyReLU)         (None, 2, 2, 50)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 1, 1, 50)      10050                                        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_25 (BatchNorm (None, 1, 1, 50)      4                                            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_28 (LeakyReLU)         (None, 1, 1, 50)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconvolution2d_13 (Deconvolutio (None, 2, 2, 50)      10050                                        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_26 (BatchNorm (None, 2, 2, 50)      8                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 2, 2, 50)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_12 (Merge)                 (None, 2, 2, 100)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_29 (LeakyReLU)         (None, 2, 2, 100)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconvolution2d_14 (Deconvolutio (None, 4, 4, 25)      10025                                        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_27 (BatchNorm (None, 4, 4, 25)      16                                           \n",
      "____________________________________________________________________________________________________\n",
      "merge_13 (Merge)                 (None, 4, 4, 50)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_30 (LeakyReLU)         (None, 4, 4, 50)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconvolution2d_15 (Deconvolutio (None, 20, 20, 5)     1005                                         \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_28 (BatchNorm (None, 20, 20, 5)     80                                           \n",
      "____________________________________________________________________________________________________\n",
      "merge_14 (Merge)                 (None, 20, 20, 10)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "leakyrelu_31 (LeakyReLU)         (None, 20, 20, 10)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "deconvolution2d_16 (Deconvolutio (None, 250, 100, 1)   41                                           \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 250, 100, 1)   0                                            \n",
      "====================================================================================================\n",
      "Total params: 94,786\n",
      "Trainable params: 94,574\n",
      "Non-trainable params: 212\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f_gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 10, 2, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_19 (InputLayer)            (None, 100, 100, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_20 (InputLayer)            (None, 100, 100, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_21 (InputLayer)            (None, 500, 100, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "f_gen (Model)                    (None, 500, 100, 1)   94786       input_19[0][0]                   \n",
      "                                                                   input_20[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "merge_31 (Merge)                 (None, 500, 100, 2)   0           input_21[0][0]                   \n",
      "                                                                   f_gen[1][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "d (Model)                        (None, 10, 2, 1)      5116        merge_31[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 99,902\n",
      "Trainable params: 99,690\n",
      "Non-trainable params: 212\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "p2p.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using trained NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x7fb4012d0cf8>,\n",
       " <keras.engine.topology.InputLayer at 0x7fb40122bef0>,\n",
       " <keras.engine.topology.InputLayer at 0x7fb40122b978>,\n",
       " <keras.engine.training.Model at 0x7fb40132ecc0>,\n",
       " <keras.engine.topology.Merge at 0x7fb4011c1240>,\n",
       " <keras.engine.training.Model at 0x7fb40124d898>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2p.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_gen.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential(name='00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
